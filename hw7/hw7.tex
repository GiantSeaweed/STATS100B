%!TEX program = xelatex
\documentclass[a4papers]{ctexart}
%数学符号
\usepackage{amssymb}
\usepackage{amsmath}
%表格
\usepackage{graphicx,floatrow}
\usepackage{array}
\usepackage{booktabs}
\usepackage{makecell}
%页边距
\usepackage{geometry}
\geometry{left=2cm,right=2cm,top=2cm,bottom=2cm}

%首行缩进两字符 利用\indent \noindent进行控制
\usepackage{indentfirst}
\setlength{\parindent}{2em}

\setromanfont{Songti SC}
%\setromanfont{Heiti SC}

\title{STATS100B--Introduction to Mathematical Statistics \\Homework 7}
\author{Feng Shiwei \ UID:305256428}
\date{}
\begin{document}
\maketitle
\section*{Question a}
\noindent Solution：\\
\indent 
\[L=\dfrac{1}{(2\pi)^{\frac{n}{2}}}|\boldsymbol{\Sigma}|^{-\frac{1}{2}} 
    e^{\frac{1}{2}(\boldsymbol{\boldsymbol{\boldsymbol{Y}}}-\mu\boldsymbol{1})'\boldsymbol{\Sigma}^{-1}(\boldsymbol{\boldsymbol{Y}}-\mu\boldsymbol{1}) }
\]
\[lnL = -\dfrac{n}{2}ln(2\pi\boldsymbol{\Sigma}^2)-\dfrac{1}{2}ln|\boldsymbol{V}|-\dfrac{1}{2\sigma^2}(\boldsymbol{Y}-\mu)V^{-1}(\boldsymbol{Y}-\mu)
 \]
 \[\dfrac {\partial \ln L}{\partial \mu }=-\dfrac {1}{2\sigma ^{2}}\left[ -\boldsymbol{Y'V^{-1}1}-\boldsymbol{1'V^{-1}Y}+2\boldsymbol{\mu 1'V^{-1}1}\right] =0
     \]
\[ \therefore \hat{\mu} = \boldsymbol{ \dfrac{1'V^{-1}Y}{1'V^{-1}1} }\]
\[ \dfrac {\partial \ln L}{\partial \sigma ^{2}}=-\dfrac {n}{2\sigma ^{2}}+\dfrac {1}{\sigma ^{4}}\left( \boldsymbol{Y}-\mu \boldsymbol{1}\right)'\boldsymbol{V}^{-1}\left( \boldsymbol{Y}-\mu \boldsymbol{1}\right) =0\]
\[\therefore \hat{\sigma^2} =\dfrac{\left( \boldsymbol{Y}-\hat{\mu} \boldsymbol{1}\right) '\boldsymbol{V}^{-1}\left( \boldsymbol{Y}-\hat{\mu} \boldsymbol{1}\right)}{n} \]


\section*{Question b}
\noindent  Solution：
\[E(\hat{\mu}) 
= E\left(\dfrac{\boldsymbol{1}'\boldsymbol{V^{-1}Y}} {\boldsymbol{1}'\boldsymbol{V^{-1}1}}\right) 
= \dfrac{\boldsymbol{1}'\boldsymbol{V}^{-1}E(\boldsymbol{Y})}{\boldsymbol{1}'\boldsymbol{V^{-1}1}} 
=\dfrac{\boldsymbol{1}'\boldsymbol{V}^{-1}\mu\boldsymbol{1}}{\boldsymbol{1}'\boldsymbol{V^{-1}1}} 
=\mu\]
\begin{alignat*}{2}
     E(\hat{\sigma^2})
     &=\dfrac {1}{n}E\left( \boldsymbol{Y}-\hat {\mu }\boldsymbol{1}\right) '\boldsymbol{V}^{-1}\left( \boldsymbol{Y}-\hat {\mu }\boldsymbol{1}\right) \\
     &=\dfrac {1}{n}E\left[ tr \left( \boldsymbol{Y}-\hat {\mu }\boldsymbol{1}\right) '\boldsymbol{V}^{-1}\left( \boldsymbol{Y}-\hat {\mu }\boldsymbol{1}\right) \right]\\
     &=\dfrac {1}{n} tr E\left[  \boldsymbol{V}^{-1}\left( \boldsymbol{Y}-\hat {\mu }\boldsymbol{1}\right)\left( \boldsymbol{Y}-\hat {\mu }\boldsymbol{1}\right)'\right]\\
     &=\dfrac {1}{n} tr \boldsymbol{V}^{-1} E\left[  \left( \boldsymbol{Y}-\hat {\mu }\boldsymbol{1}\right)\left( \boldsymbol{Y}-\hat {\mu }\boldsymbol{1}\right)'\right]\\
     &=\dfrac {1}{n} tr \boldsymbol{V}^{-1} \left[ var\left( \boldsymbol{Y}-\hat {\mu }\boldsymbol{1}\right) +E\left( \boldsymbol{Y}-\hat {\mu }\boldsymbol{1}\right) E\left( Y-\hat {\mu }1\right) \right] \\
     &=\dfrac {1}{n} tr\left[ \boldsymbol{V}^{-1}  var\left( \boldsymbol{Y}-\hat {\mu }\boldsymbol{1}\right) \right] \\
\end{alignat*}
\begin{alignat*}{2}
    var\left( \boldsymbol{Y}-\hat {\mu }\boldsymbol{1}\right)
    &= var\left( \boldsymbol{Y}-\dfrac {\boldsymbol{1}\boldsymbol{V}^{-1}\boldsymbol{Y}}{\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}}\boldsymbol{1}\right) \\
    &= var\left( \boldsymbol{Y}-\dfrac {\boldsymbol{1}\boldsymbol{1}\boldsymbol{V}^{-1}\boldsymbol{Y}}{\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}}\right) \\
    &= var\left[\left( \boldsymbol{I}-\dfrac {\boldsymbol{1}\boldsymbol{1}'\boldsymbol{V}^{-1}}{\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}}\right) \boldsymbol{Y}\right] \\
    &= \left( \boldsymbol{I}-\dfrac {\boldsymbol{1}\boldsymbol{1}'\boldsymbol{V}^{-1}}{\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}}\right) \sigma ^{2}\boldsymbol{V}\left( 1-\dfrac {\boldsymbol{1}\boldsymbol{1}'\boldsymbol{V}^{-1}}{\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}}\right) ^{'}\\
    &=\sigma^2 \left( \boldsymbol{V}-\dfrac {\boldsymbol{1}\boldsymbol{1}'}{\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}}\right)
\end{alignat*}
\begin{alignat*}{2}
    \therefore 
    E(\hat{\sigma^2})
    &=\dfrac {1}{n} tr\left[ \boldsymbol{V}^{-1}  var\left( \boldsymbol{Y}-\hat {\mu }\boldsymbol{1}\right) \right] \\
    &=\dfrac {1}{n}\sigma ^{2}\left[ tr\boldsymbol{V}^{-1}\boldsymbol{V}-tr\dfrac {\boldsymbol{V}^{-1}\boldsymbol{1}\boldsymbol{1}'}{\boldsymbol{1}'\boldsymbol{V}\boldsymbol{1}}\right] \\
    &=\dfrac{1}{n}\sigma^2\left( n-\dfrac{\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}'}{\boldsymbol{1}'\boldsymbol{V}\boldsymbol{1}} \right)\\
    &= \dfrac{n-1}{n}\sigma^2
\end{alignat*}


\section*{Question c}
\noindent Solution:
\[ \boldsymbol{I}(\boldsymbol{\theta}) = -E \begin{pmatrix}
    \dfrac {\partial ^{2}\ln L}{\partial \mu^2} 
    & \dfrac {\partial^{2}\ln L}{\partial \mu \partial \sigma ^{2}} \\ \\
    \dfrac {\partial ^{2}\ln L}{\partial \sigma ^{2}\partial \mu } 
    & \dfrac {\partial \ln L}{\partial {\sigma ^{2}}^{(2)} }
\end{pmatrix}\]
\[  \dfrac {\partial ^{2}\ln L}{\partial \mu^2 }=-\dfrac {\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}}{\sigma ^{2}} \]
\[ \dfrac {\partial^{2}\ln L}{\partial \mu \partial \sigma ^{2}}=\dfrac {1}{\sigma ^{4}}\left[ \mu \boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}-\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{Y}\right] \]
\[ \dfrac {\partial ^{2}\ln L}{\partial \sigma ^{2}\partial \mu } = \dfrac {1}{\sigma ^{4}}\left[ \mu \boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}-\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{Y}\right] \]
\[ \dfrac {\partial \ln L}{\partial {\sigma ^{2}}^{(2)} } =\dfrac {n}{2\sigma ^{4}}-\dfrac {1}{\sigma ^{6}}\left( \boldsymbol{Y}-\mu \boldsymbol{1}\right) '\boldsymbol{V}^{-1}\left( \boldsymbol{Y}-\mu \boldsymbol{1}\right)  \]
\[ \therefore \boldsymbol{I}^{-1}(\boldsymbol{\theta}) =\begin{pmatrix}
\dfrac{\sigma^2}{\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}}   &   0        \\
0                             &   \dfrac{2\sigma^2}{n}
\end{pmatrix} ,\,\,
var(\hat{\sigma^2})\ge -\dfrac{1}{E\left(\dfrac {\partial ^{2}\ln L}{\partial \mu^2 }\right)} = \dfrac {\sigma ^{2}}{\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}}
\]

\[\because E\left( \hat {\mu }\right) =\mu,\,\,
var\left( \hat {\mu }\right) 
=var\left( \dfrac {\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{Y}}{\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}}\right) 
=\dfrac {var\left[ \left( \boldsymbol{1}'\boldsymbol{V}^{-1}\right) \boldsymbol{Y}\right] }{\left( \boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}\right) ^{2}}
=\dfrac {\left( \boldsymbol{1}'\boldsymbol{V}^{-1}\right) \sigma ^{2}\boldsymbol{V}\left( \boldsymbol{1}'\boldsymbol{V}^{-1}\right)'}{\left( \boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}\right) ^{2}}
=\dfrac {\sigma ^{2}}{\boldsymbol{1}'\boldsymbol{V}^{-1}\boldsymbol{1}}
\]
\[\therefore \hat{\mu}\,\,is\,\,efficient.\]

\section*{Question d}
\noindent Solution:
\[ f\left( y_{i}\right) =\dfrac {1}{\sqrt {2\pi }i\sigma }e^{-\frac {\left( y-i\theta \right) ^{2}}{2\left( i\sigma \right) ^{2}}}\]
\[ L=\prod ^{n}_{i=1}f\left( y_{i}\right) =\left( 2\pi \right) ^{-\frac {n}{2}}\prod ^{n}_{i=1}i\sigma ^{-n}e^{-\frac {1}{2\sigma^2}\sum ^{n}_{i=1}\left( \frac {y_{i}-i\theta }{i}\right) ^{2}}\]
\[ \ln L=-\dfrac {n}{2}\ln 2\pi +\sum ^{n}_{i=1}\ln i-n\ln \sigma -\dfrac {1}{2\sigma ^{2}}\sum ^{n}_{i=1}\left( \theta -\dfrac {y_{i}}{i}\right) ^{2} \]
\[ \dfrac {\partial \ln L}{\partial \theta }=-\dfrac {1}{\sigma ^{2}}\sum ^{n}_{i=1}\left( \theta -\dfrac {y_{i}}{i}\right) =0\]
\[\therefore \hat {\theta }=\dfrac {1}{n}\sum ^{n}_{i=1}\dfrac {y_{i}}{i}\]
% \[ E\left( \hat {\theta }\right) =\dfrac {1}{n}\sum ^{n}_{i=1}\dfrac {E\left( y_{i}\right) }{i}=\dfrac {1}{n}.\sum ^{n}_{i=1}\dfrac {i\theta }{i}=\theta \]
\[ var\left( \hat {\theta }\right) =\dfrac {1}{n^{2}}\sum \dfrac {var\left( y_{i}\right) }{i^{2}}=\dfrac {1}{n^{2}}\sum ^{n}_{i=1}\dfrac {i^{2}\sigma ^{2}}{i^{2}}=\dfrac{\sigma ^{2}}{n} \]
\[ \because \dfrac {\partial ^{2}\ln L}{\partial \theta ^{2}}=-\dfrac {n}{\sigma ^{2}},\, var\left( \hat {\theta }\right) \geq -\dfrac {1}{E\left( \dfrac {\partial ^{2}\ln L}{\partial \theta ^{2}}\right) }=-\dfrac{1}{-\dfrac{1}{\sigma^2}n}=\dfrac {\sigma ^{2}}{n}\]
\[ \therefore \hat{\theta}\,\, is\,\, an\,\, efficient\,\, estimator.\]


\section*{Question e}
Suppose the radius equals $R$.\,\,$R_i = R+\epsilon_i,\,\epsilon\sim N(0,\sigma),\,\, i=1,2,\cdots n.$
\[ E(\bar{R}) =\dfrac{1}{n}\sum_{i=1}^n E(R+\epsilon_1) = \dfrac{1}{n}\sum_{i=1}^n R+E(\epsilon_1) = R\]
\[ E(\bar{R}^2) = var(\bar{R})+(E\bar{R})^2 = \dfrac{1}{n^2}\sum_{i=1}^n var(R+\epsilon_1) + R^2 =\dfrac{\sigma^2}{n}+R^2\] 
\[ \therefore Define\,\,\hat{R^2} = \bar{R}^2-\dfrac{S^2}{n},\,E(\hat{R^2})=R^2 \]
\[\therefore The \,\, unbiased \,\, estimator\,\,  of\,\,  area\,\,  is \,\, \hat{A} = \pi\left(\bar{R}^2-\dfrac{S^2}{n}\right)\]


\section*{Question f}
\[X=Y^2\]
\begin{alignat*}{5}
    F_X(x)&=P(X\le x)\\
    &=P(Y\le \sqrt{x})\\
    &=\int_0^{\sqrt{x}} \dfrac{2y}{\theta}e^{-\frac{y^2}{\theta}}\mathrm{d}y
\end{alignat*}
\[  f(x)=F'_X(x)=\dfrac{1}{\theta}e^{-\frac{x}{\theta}}\]
\[\therefore Y^2 \sim exp\left(\dfrac{1}{\theta}\right)\]
\[ var(\hat{\theta}) = \dfrac{1}{n^2}\sum_{i=0}^n var(Y_i^2)=\dfrac{1}{n^2}n\theta^2 = \dfrac{\theta^2}{n}\]
\[\because \dfrac {\partial ^{2}\ln f\left( x\right) }{\partial \theta ^{2}}=\dfrac {1}{\theta ^{2}}-\dfrac {2x}{\theta ^{3}}\]
\[var(\hat{\theta}) \ge -\dfrac{1}{nE(\dfrac {1}{\theta ^{2}}-\dfrac {2x}{\theta ^{3}})}
= -\dfrac{1}{nE\left(\dfrac {1}{\theta ^{2}}-\dfrac {2E(x)}{\theta ^{3}}\right)} =\dfrac{\theta^2}{n}\]
\[\therefore \hat{\theta}\,\, is\,\, efficient\]


\section*{Question g}
\[E\left( T-\theta \right) ^{2}=var\left( T\right) +B^{2}\]
\begin{alignat*}{2}
    var(T) &= var(\alpha_1\bar{X}+\alpha_2cS)\\
        &= \alpha_1^2var(\bar{X})+\alpha_2^2var(cS)\\
        &= \alpha_1^2\dfrac{\theta^2}{n}+\alpha_2^2(c^2-1)\theta^2
\end{alignat*}
\[B=E(T)-\theta=(\alpha_1+\alpha_2-1)\theta\]
\[\therefore E\left( T-\theta \right) ^{2} = \left[ \dfrac {\alpha ^{2}_{1}}{n}+\left( c^{2}-1\right) \alpha ^{2}_{2}+\left( \alpha _{1}+\alpha _{2}-1\right) ^{2}\right] \theta ^{2} \]
\begin{equation*}
\begin{cases}
    \dfrac {\partial E\left( T-\theta \right) ^{2}}{\partial \alpha _{1}}=\dfrac {2\alpha _{1}}{n}+2\left( \alpha _{1}+\alpha _{2}-1\right) =0 \\
    \dfrac {\partial E\left( T-\theta \right) ^{2}}{\partial \alpha _{2}}=2\left( c^{2}-1\right) \alpha _{2}+2\left( \alpha _{1}+\alpha _{2}-1\right) =0
\end{cases}
\end{equation*}
\begin{equation*}
    \therefore \begin{cases}
        \alpha_1 = \dfrac{n(c^2-1)}{(n+1)(c^2-1)+1}\\
        \alpha_2 = \dfrac{1}{(n+1)(c^2-1)+1}
    \end{cases}
\end{equation*}
\[A=\dfrac {\partial ^{2}E}{\partial \alpha_1^2}=\dfrac {2}{n}+2,B=\dfrac {\partial ^{2}E}{\partial \alpha _{1}\partial \alpha _{2}}=2,C=\dfrac {\partial ^{2}E}{\partial \alpha ^{2}_{2}}=2c^{2}\]
\[\because A<0,\,B^2-AC=4\left[1-\dfrac{n+1}{n}c^2\right]<0 \,(Using\,\, WolframAlpha) \]
\[\therefore E\left( T-\theta \right) ^{2} gets\,\, the\,\, minimum \,\,when\,\, \alpha_1\,\, and \,\,\alpha_2 \,\,equal\,\, the\,\, above\,\, values.\]
\[\therefore T=\dfrac{n(c^2-1)}{(n+1)(c^2-1)+1}\bar{X} + \dfrac{1}{(n+1)(c^2-1)+1}cS\,\, is\,\, the\,\, estimator\,\, that\,\, minimizes\,\, E\left( T-\theta \right) ^{2}\]

\end{document}