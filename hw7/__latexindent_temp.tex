%!TEX program = xelatex
\documentclass[a4papers]{ctexart}
%数学符号
\usepackage{amssymb}
\usepackage{amsmath}
%表格
\usepackage{graphicx,floatrow}
\usepackage{array}
\usepackage{booktabs}
\usepackage{makecell}
%页边距
\usepackage{geometry}
\geometry{left=2cm,right=2cm,top=2cm,bottom=2cm}

%首行缩进两字符 利用\indent \noindent进行控制
\usepackage{indentfirst}
\setlength{\parindent}{2em}

\setromanfont{Songti SC}
%\setromanfont{Heiti SC}

\title{STATS100B--Introduction to Mathematical Statistics \\Homework 6}
\author{Feng Shiwei \ UID:305256428}
\date{}
\begin{document}
\maketitle
\section*{Question a}
\noindent Solution：\\
\indent 
\[E(\bar{X}) = \mu = \lambda,\, E(S^2)=\sigma^2=\lambda\]
\[ f(x) = \dfrac {\lambda ^{x}e^{-\lambda }}{x!}\]
\[\ln f\left( x\right) =x\ln \lambda -\lambda -\ln x!\]
\[\dfrac {\partial \ln f\left( x\right) }{\partial \lambda }=\dfrac {x}{\lambda }-1\]
\[\dfrac {\partial ^{2}\ln f\left( x\right) }{\partial \lambda ^{2}}=-\dfrac {x}{\lambda ^{2}}\]
Let's find the Cramer-Rao Lower Bound.
\[var\left( \hat {\lambda }\right) \ge -\dfrac {1}{nE\left( -\dfrac {x}{\lambda ^{2}}\right) }=\dfrac {\lambda ^{2}}{n\lambda }=\dfrac {\lambda }{n}\]
\[\because var(\bar{X})=\dfrac{\sigma^2}{n}=\dfrac{\lambda}{n} \]
\[\therefore var(\sigma^2)\ge var(\bar{X})\]
So $\bar{X}$ is a better estimator.

\section*{Question b}
\noindent  Solution：
\begin{alignat*}{2}
 E\left( \alpha \bar {X}+\left( 1-\alpha \right) cS \right) 
 &= \alpha E\left( \bar {X}\right) +\left( 1-\alpha \right) E\left( cS\right) 
 &=\alpha \theta +\left( 1-\alpha \right) \theta
 &=\theta 
\end{alignat*}
\[var\left( \alpha \bar {X}+\left( 1-\alpha \right) cS\right) =\alpha \cdot var\left( \bar {X}\right) +\left( 1-\alpha \right) ^{2}\cdot var\left( cS\right) \]
\[\dfrac {\mathrm{d} var\left( \alpha \bar {X}+\left( 1-\alpha \right) cS\right) }{\mathrm{d}\alpha }
    = 2\alpha \cdot var\left( \bar {X}\right) +2\left( \alpha -1\right) \cdot var\left( S\right) 
    = 0
\]
\[\alpha =\dfrac {var\left( cS\right) }{var\left( cS\right) +var\left( \bar {X}\right) }\]
\[ \because var(\bar{X}) = \dfrac{\theta^2}{n},\,
var(cS)=E(c^2S^2)-(E(cS))^2=c^2\theta^2-\theta^2=(c^2-1)\theta^2 \]
\[\therefore \alpha = \dfrac{n(c^2-1)}{n(c^2-1)+1} \]



\section*{Question c}
\noindent Solution:
\[X\sim (\alpha,\beta),\,\bar{X}\sim(n\alpha,\dfrac{\beta}{n})\]
\[E\Big(\dfrac{1}{\bar{X}}\Big) = \dfrac{\Gamma(n\alpha-1)\Big(\dfrac{\beta}{n}\Big)^{-1}}{\Gamma(n\alpha)}
= \dfrac{n}{(n\alpha-1)\beta}\]
\[\therefore \hat{\theta} = \dfrac{n\alpha-1}{n\bar{X}},\,
E( \hat{\theta} ) = \dfrac{n\alpha-1}{n} E\Big(\dfrac{1}{\bar{X}}\Big) = \dfrac{1}{\beta}  \]

\section*{Question d}
\noindent Solution:
\begin{alignat*}{2}
    \sum_{i=1}^{4}\left( X_{i}-\bar {X}\right) ^{2}
    &=\sum ^{4}_{i=1}X^{2}_{i}-4\bar {X}^{2}\\
    &=\sum ^{4}_{i=1}X^{2}_{i}-4\Big[ \dfrac{1}{4}(X_1+X_2+X_3+X_4) \Big]^{2}\\  
    &=\sum ^{4}_{i=1}X^{2}_{i}-\dfrac {1}{2}\left( \sum ^{4}_{i=1}X^{2}_{i}+2\sum _{1\leq i < j\leq 4}X_{i}X_{j}\right) \\
    &=\dfrac {3}{4}\sum ^{4}_{i=1}X^{2}_{i}-\dfrac {1}{2}\sum _{1\leq i < j\leq 4}X_{i}X_{j}
\end{alignat*}
\begin{alignat*}{2}
    RHS  
    &=\Big( \dfrac {1}{2}X_1^{2}-X_{1}X_{2}+\dfrac {1}{2}X^{2}_{2} \Big)
     +\Big( \dfrac {2}{3}X^{2}_{3}+\dfrac {1}{6}\left( X_{1}+X_{2}\right) ^{2}-\dfrac {2}{3}X_{3}\left( X_{1}+X_{2}\right) \Big)
     +\dfrac{3}{4}\Big( X_4-\dfrac{1}{3}(X_1+X_2+X_3) \Big)^2\\
    &=\cdots \cdots(simple\, but\, tedious\, simplifications)\\
    &=\dfrac {3}{4}\sum ^{4}_{i=1}X^{2}_{i}-\dfrac {1}{2}\sum _{1\leq i < j\leq 4}X_{i}X_{j}
\end{alignat*}
\[\therefore 
\sum_{i=1}^{4}\left( X_{i}-\bar {X}\right) ^{2}=
\dfrac {\left( X_{1}-X_{2}\right) ^{2}}{2}+\dfrac {\left[ X_{3}-\frac {\left( X_{1}+X_{2}\right) }{2}\right] ^{2}}{\frac {3}{2}}
    \dfrac {\left[ X_{4}-\frac {\left( X_{1}+X_{2}+X_{3}\right) }{3}\right] ^{2}}{\frac {4}{3}}
  \]

\[\because X_1-X_2\sim N(0,\sqrt{2})\]
\[\therefore \dfrac{(X_1-X_2)^2}{2}\sim \chi_1^2\]
\[\because X_3-\dfrac{X_1+X_2}{2}\sim N(0,\sqrt{\dfrac{3}{2}})\]
\[\therefore \dfrac{(X_3-\frac{X_1+X_2}{2})^2}{\frac{3}{2}} \sim \chi_1^2\]
\[\because X_4-\dfrac{X_1+X_2+X_3}{3}\sim N(0,\sqrt{\dfrac{4}{3}})\]
\[\therefore \dfrac{(X_4-\frac{X_1+X_2+X_3}{3})^2}{\frac{4}{3}} \sim \chi_1^2\]

  \[ \boldsymbol{X}=
    \begin{pmatrix}X_1 & X_2 & X_3 &X_4 \end{pmatrix} '
    \]
\[
    \begin{pmatrix}X_1-X_2 \\ X_3-\frac{X_1+X_2}{2} \\ X_4-\frac{X_1+X_2+X3}{3} \end{pmatrix}
    = \begin{pmatrix} 1 & -1 & 0 & 0 \\
                     -\frac{1}{2} & -\frac{1}{2} & 1 & 0 \\
                     -\frac{1}{3} & -\frac{1}{3} & -\frac{1}{3} & 1
    \end{pmatrix} \begin{pmatrix}X_1 \\ X_2 \\ X_3 \\ X_4\end{pmatrix}
    =\boldsymbol{AX}
    \]
\[
    var( \boldsymbol{AX} ) = \boldsymbol{A}var(\boldsymbol{X})\boldsymbol{A}'
= \begin{pmatrix} 1 & -1 & 0 & 0 \\
                     -\frac{1}{2} & -\frac{1}{2} & 1 & 0 \\
                     -\frac{1}{3} & -\frac{1}{3} & -\frac{1}{3} & 1
    \end{pmatrix}
    \begin{pmatrix} 1 & 0 & 0 & 0 \\
                    0 & 1 & 0 & 0 \\
                    0 & 0 & 1 & 0 \\
                    0 & 0 & 0 & 1 \\
    \end{pmatrix}
    \begin{pmatrix} 1 & -\frac{1}{2} & -\frac{1}{3} \\
                    -1 & -\frac{1}{2} & -\frac{1}{3}\\
                    0 & 1 & -\frac{1}{3}\\
                    0 & 0 & 1\\
    \end{pmatrix}
=    \begin{pmatrix} 2 & 0 & 0 \\
                    0 & \frac{3}{2} & 0  \\
                    0 & 0 & \frac{4}{3}  \\
    \end{pmatrix}
\]
So the three terms in the RHS are independent each with a $\chi_1^2$ distribution.

\end{document}